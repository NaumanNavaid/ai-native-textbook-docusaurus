"use strict";(globalThis.webpackChunkai_native_textbook_docusaurus=globalThis.webpackChunkai_native_textbook_docusaurus||[]).push([[3343],{3266:(n,r,e)=>{e.r(r),e.d(r,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"part-3-simulation/chapter-8-unity-robotics-visualization","title":"Unity for Robotics Visualization","description":"Introduction","source":"@site/docs/part-3-simulation/chapter-8-unity-robotics-visualization.mdx","sourceDirName":"part-3-simulation","slug":"/part-3-simulation/chapter-8-unity-robotics-visualization","permalink":"/ai-native-textbook-docusaurus/docs/part-3-simulation/chapter-8-unity-robotics-visualization","draft":false,"unlisted":false,"editUrl":"https://github.com/NaumanNavaid/ai-native-textbook-docusaurus/tree/main/docs/part-3-simulation/chapter-8-unity-robotics-visualization.mdx","tags":[],"version":"current","frontMatter":{"title":"Unity for Robotics Visualization","part":3,"chapter":8,"difficulty":"intermediate","estimatedTime":50,"prerequisites":["chapter-7-gazebo-physics-simulation"],"objectives":["Understand Unity as a robotics visualization platform","Learn Unity-ROS integration and data pipelines","Master photorealistic rendering and simulation","Create interactive robotics applications"]},"sidebar":"chaptersSidebar","previous":{"title":"Gazebo Physics Simulation","permalink":"/ai-native-textbook-docusaurus/docs/part-3-simulation/chapter-7-gazebo-physics-simulation"},"next":{"title":"NVIDIA Isaac Sim & Synthetic Data","permalink":"/ai-native-textbook-docusaurus/docs/part-3-simulation/chapter-9-nvidia-isaac-synthetic-data"}}');var i=e(4848),o=e(8453);const a={title:"Unity for Robotics Visualization",part:3,chapter:8,difficulty:"intermediate",estimatedTime:50,prerequisites:["chapter-7-gazebo-physics-simulation"],objectives:["Understand Unity as a robotics visualization platform","Learn Unity-ROS integration and data pipelines","Master photorealistic rendering and simulation","Create interactive robotics applications"]},s="Chapter 8: Unity Robotics and Visualization",l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"8.1 Unity for Robotics Overview",id:"81-unity-for-robotics-overview",level:2},{value:"8.1.1 Why Unity for Robotics?",id:"811-why-unity-for-robotics",level:3},{value:"8.1.2 Unity vs Gazebo Comparison",id:"812-unity-vs-gazebo-comparison",level:3},{value:"8.2 Unity-ROS Integration",id:"82-unity-ros-integration",level:2},{value:"8.2.1 ROS-TCP-Connector",id:"821-ros-tcp-connector",level:3},{value:"8.2.2 Advanced ROS Integration",id:"822-advanced-ros-integration",level:3},{value:"8.3 Photorealistic Rendering",id:"83-photorealistic-rendering",level:2},{value:"8.3.1 High Definition Render Pipeline (HDRP)",id:"831-high-definition-render-pipeline-hdrp",level:3},{value:"8.3.2 Material System for Robotics",id:"832-material-system-for-robotics",level:3},{value:"8.4 Interactive Robotics Applications",id:"84-interactive-robotics-applications",level:2},{value:"8.4.1 Virtual Robot Control Interface",id:"841-virtual-robot-control-interface",level:3},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 8.1: Unity-ROS Integration",id:"exercise-81-unity-ros-integration",level:3},{value:"Exercise 8.2: Photorealistic Rendering",id:"exercise-82-photorealistic-rendering",level:3},{value:"Exercise 8.3: Interactive Control Interface",id:"exercise-83-interactive-control-interface",level:3},{value:"Exercise 8.4: Material System",id:"exercise-84-material-system",level:3},{value:"Exercise 8.5: Cross-Platform Deployment",id:"exercise-85-cross-platform-deployment",level:3},{value:"Glossary Terms",id:"glossary-terms",level:2}];function m(n){const r={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.header,{children:(0,i.jsx)(r.h1,{id:"chapter-8-unity-robotics-and-visualization",children:"Chapter 8: Unity Robotics and Visualization"})}),"\n",(0,i.jsx)(r.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(r.p,{children:"Unity has emerged as a powerful platform for robotics visualization, offering photorealistic rendering, advanced physics simulation, and extensive customization capabilities. While Gazebo dominates the research simulation space, Unity excels in visualization, human-robot interaction, and synthetic data generation. This chapter explores how to leverage Unity's capabilities for robotics applications, from real-time visualization to interactive training environments."}),"\n",(0,i.jsx)(r.admonition,{type:"info",children:(0,i.jsx)(r.p,{children:"Unity's strength lies in its rendering pipeline and cross-platform deployment, making it ideal for robotics applications requiring high-fidelity visualization, user interaction, and mobile deployment."})}),"\n",(0,i.jsx)(r.h2,{id:"81-unity-for-robotics-overview",children:"8.1 Unity for Robotics Overview"}),"\n",(0,i.jsx)(r.h3,{id:"811-why-unity-for-robotics",children:"8.1.1 Why Unity for Robotics?"}),"\n",(0,i.jsx)(r.p,{children:"Unity offers unique advantages for robotics applications:"}),"\n",(0,i.jsx)(r.p,{children:(0,i.jsx)(r.strong,{children:"Diagram: Unity Robotics Ecosystem"})}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"Unity Engine\r\n\u251c\u2500\u2500 Rendering Pipeline\r\n\u2502   \u251c\u2500\u2500 Photorealistic Graphics\r\n\u2502   \u251c\u2500\u2500 Real-time Lighting\r\n\u2502   \u251c\u2500\u2500 Post-processing Effects\r\n\u2502   \u2514\u2500\u2500 VR/AR Support\r\n\u251c\u2500\u2500 Physics System\r\n\u2502   \u251c\u2500\u2500 NVIDIA PhysX\r\n\u2502   \u251c\u2500\u2500 Custom Physics Materials\r\n\u2502   \u251c\u2500\u2500 Collision Detection\r\n\u2502   \u2514\u2500\u2500 Vehicle Physics\r\n\u251c\u2500\u2500 Scripting System\r\n\u2502   \u251c\u2500\u2500 C# Scripts\r\n\u2502   \u251c\u2500\u2500 Visual Scripting\r\n\u2502   \u251c\u2500\u2500 Animation Controller\r\n\u2502   \u2514\u2500\u2500 Timeline System\r\n\u251c\u2500\u2500 Cross-Platform Support\r\n\u2502   \u251c\u2500\u2500 Windows/Linux/macOS\r\n\u2502   \u251c\u2500\u2500 iOS/Android\r\n\u2502   \u251c\u2500\u2500 VR Platforms\r\n\u2502   \u2514\u2500\u2500 Web Browsers\r\n\u2514\u2500\u2500 Asset Pipeline\r\n    \u251c\u2500\u2500 3D Model Import\r\n    \u251c\u2500\u2500 Material System\r\n    \u251c\u2500\u2500 Animation System\r\n    \u2514\u2500\u2500 Audio Integration\n"})}),"\n",(0,i.jsx)(r.h3,{id:"812-unity-vs-gazebo-comparison",children:"8.1.2 Unity vs Gazebo Comparison"}),"\n",(0,i.jsx)(r.p,{children:(0,i.jsx)(r.strong,{children:"Diagram: Unity vs Gazebo Comparison"})}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"Gazebo\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 Strengths:                             \u2502\r\n\u2502 \u2022 Accurate physics simulation           \u2502\r\n\u2502 \u2022 Realistic sensor modeling             \u2502\r\n\u2502 \u2022 ROS 2 integration                    \u2502\r\n\u2502 \u2022 Open source                          \u2502\r\n\u2502 \u2022 Robotics-focused                     \u2502\r\n\u2502                                         \u2502\r\n\u2502 Best for:                             \u2502\r\n\u2502 \u2022 Algorithm testing                     \u2502\r\n\u2502 \u2022 Sensor simulation                   \u2502\r\n\u2502 \u2022 Autonomous navigation                \u2502\r\n\u2502 \u2022 Multi-robot systems                  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\r\nUnity\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 Strengths:                             \u2502\r\n\u2502 \u2022 Photorealistic rendering              \u2502\r\n\u2502 \u2022 User interaction                      \u2502\r\n\u2502 \u2022 Mobile deployment                    \u2502\r\n\u2502 \u2022 Asset ecosystem                      \u2502\r\n\u2502 \u2022 Visual scripting                      \u2502\r\n\u2502                                         \u2502\r\n\u2502 Best for:                             \u2502\r\n\u2502 \u2022 Human-robot interaction               \u2502\r\n\u2502 \u2022 Training and education               \u2502\r\n\u2502 \u2022 Synthetic data generation            \u2502\r\n\u2502 \u2022 Commercial applications               \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsx)(r.h2,{id:"82-unity-ros-integration",children:"8.2 Unity-ROS Integration"}),"\n",(0,i.jsx)(r.h3,{id:"821-ros-tcp-connector",children:"8.2.1 ROS-TCP-Connector"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",metastring:'title="Unity ROS Connection Script"',children:'using UnityEngine;\r\nusing System.Collections.Generic;\r\nusing RosSharp.RosBridgeClient;\r\nusing std_msgs = RosSharp.RosBridgeClient.std_msgs;\r\nusing geometry_msgs = RosSharp.RosBridgeClient.geometry_msgs;\r\nusing sensor_msgs = RosSharp.RosBridgeClient.sensor_msgs;\r\n\r\npublic class UnityROSConnector : MonoBehaviour\r\n{\r\n    [Header("ROS Connection Settings")]\r\n    public string rosBridgeURL = "ws://localhost:9090";\r\n    public bool autoConnect = true;\r\n\r\n    [Header("Publishing Settings")]\r\n    public float publishRate = 30.0f;\r\n    public string robotFrameId = "base_link";\r\n\r\n    [Header("Subscribing Settings")]\r\n    public bool subscribeOdometry = true;\r\n    public bool subscribeLaserScan = true;\r\n    public bool subscribeCameraImage = true;\r\n\r\n    private RosSocket rosSocket;\r\n    private float lastPublishTime;\r\n    private bool isConnected = false;\r\n\r\n    // Publishers\r\n    private string robotPoseTopic = "/unity/robot_pose";\r\n    private string interactionTopic = "/unity/interaction";\r\n\r\n    // Subscribers\r\n    private string odomTopic = "/odom";\r\n    private string scanTopic = "/laser/scan";\r\n    private string cameraTopic = "/camera/image_raw";\r\n\r\n    // Robot state\r\n    public Vector3 robotPosition = Vector3.zero;\r\n    public Quaternion robotRotation = Quaternion.identity;\r\n\r\n    // Object references\r\n    [SerializeField] private Transform robotTransform;\r\n    [SerializeField] private GameObject laserScanner;\r\n    [SerializeField] private Material laserMaterial;\r\n\r\n    void Start()\r\n    {\r\n        if (autoConnect)\r\n        {\r\n            ConnectToROS();\r\n        }\r\n    }\r\n\r\n    void Update()\r\n    {\r\n        if (!isConnected) return;\r\n\r\n        // Update robot position\r\n        if (robotTransform != null)\r\n        {\r\n            robotPosition = robotTransform.position;\r\n            robotRotation = robotTransform.rotation;\r\n        }\r\n\r\n        // Publish robot pose\r\n        if (Time.time - lastPublishTime > 1.0f / publishRate)\r\n        {\r\n            PublishRobotPose();\r\n            lastPublishTime = Time.time;\r\n        }\r\n    }\r\n\r\n    public void ConnectToROS()\r\n    {\r\n        rosSocket = new RosSocket(rosBridgeURL);\r\n\r\n        // Add connection event handlers\r\n        rosSocket.OnConnected += () => {\r\n            isConnected = true;\r\n            Debug.Log("Connected to ROS Bridge");\r\n\r\n            // Subscribe to topics\r\n            if (subscribeOdometry)\r\n                SubscribeToOdometry();\r\n            if (subscribeLaserScan)\r\n                SubscribeToLaserScan();\r\n            if (subscribeCameraImage)\r\n                SubscribeToCameraImage();\r\n        };\r\n\r\n        rosSocket.OnClosed += () => {\r\n            isConnected = false;\r\n            Debug.Log("Disconnected from ROS Bridge");\r\n        };\r\n\r\n        rosSocket.OnError += (error) => {\r\n            Debug.LogError($"ROS Bridge Error: {error}");\r\n        };\r\n\r\n        rosSocket.Connect();\r\n    }\r\n\r\n    public void DisconnectFromROS()\r\n    {\r\n        if (rosSocket != null)\r\n        {\r\n            rosSocket.Close();\r\n            isConnected = false;\r\n        }\r\n    }\r\n\r\n    #region Publishers\r\n\r\n    private void PublishRobotPose()\r\n    {\r\n        var poseMsg = new geometry_msgs.PoseStamped\r\n        {\r\n            header = new std_msgs.Header\r\n            {\r\n                frame_id = robotFrameId,\r\n                stamp = RosSharp.RosBridgeClient.RosTime.Now()\r\n            }\r\n        };\r\n\r\n        // Convert Unity coordinate system to ROS\r\n        poseMsg.pose.position = new geometry_msgs.Point\r\n        {\r\n            x = robotPosition.z,\r\n            y = -robotPosition.x,\r\n            z = robotPosition.y\r\n        };\r\n\r\n        poseMsg.pose.orientation = new geometry_msgs.Quaternion\r\n        {\r\n            x = -robotRotation.y,\r\n            y = -robotRotation.z,\r\n            z = robotRotation.x,\r\n            w = robotRotation.w\r\n        };\r\n\r\n        rosSocket.Publish(robotPoseTopic, poseMsg);\r\n    }\r\n\r\n    public void PublishInteractionEvent(string eventType, object data)\r\n    {\r\n        var interactionMsg = new UnityInteractionMessage\r\n        {\r\n            timestamp = Time.time,\r\n            event_type = eventType,\r\n            data = data.ToString()\r\n        };\r\n\r\n        rosSocket.Publish(interactionTopic, interactionMsg);\r\n    }\r\n\r\n    #endregion\r\n\r\n    #region Subscribers\r\n\r\n    private void SubscribeToOdometry()\r\n    {\r\n        rosSocket.Subscribe<nav_msgs.Odometry>(odomTopic, HandleOdometry);\r\n    }\r\n\r\n    private void SubscribeToLaserScan()\r\n    {\r\n        rosSocket.Subscribe<sensor_msgs.LaserScan>(scanTopic, HandleLaserScan);\r\n    }\r\n\r\n    private void SubscribeToCameraImage()\r\n    {\r\n        rosSocket.Subscribe<sensor_msgs.Image>(cameraTopic, HandleCameraImage);\r\n    }\r\n\r\n    #endregion\r\n\r\n    #region Message Handlers\r\n\r\n    private void HandleOdometry(nav_msgs.Odometry odom)\r\n    {\r\n        // Convert ROS coordinate system to Unity\r\n        Vector3 newPosition = new Vector3(\r\n            -odom.pose.pose.position.y,\r\n            odom.pose.pose.position.z,\r\n            odom.pose.pose.position.x\r\n        );\r\n\r\n        Quaternion newRotation = new Quaternion(\r\n            odom.pose.pose.orientation.z,\r\n            -odom.pose.pose.orientation.y,\r\n            -odom.pose.pose.orientation.x,\r\n            odom.pose.pose.orientation.w\r\n        );\r\n\r\n        // Update robot transform\r\n        if (robotTransform != null)\r\n        {\r\n            robotTransform.position = newPosition;\r\n            robotTransform.rotation = newRotation;\r\n        }\r\n    }\r\n\r\n    private void HandleLaserScan(sensor_msgs.LaserScan scan)\r\n    {\r\n        if (laserScanner != null && laserMaterial != null)\r\n        {\r\n            // Create laser visualization\r\n            VisualizeLaserScan(scan);\r\n        }\r\n    }\r\n\r\n    private void HandleCameraImage(sensor_msgs.Image image)\r\n    {\r\n        // Process camera image\r\n        ProcessCameraImage(image);\r\n    }\r\n\r\n    #endregion\r\n\r\n    #region Visualization\r\n\r\n    private void VisualizeLaserScan(sensor_msgs.LaserScan scan)\r\n    {\r\n        // Create line renderer for laser scan\r\n        LineRenderer lineRenderer = laserScanner.GetComponent<LineRenderer>();\r\n        if (lineRenderer == null)\r\n        {\r\n            lineRenderer = laserScanner.AddComponent<LineRenderer>();\r\n        }\r\n\r\n        lineRenderer.positionCount = scan.ranges.Length + 1;\r\n        lineRenderer.material = laserMaterial;\r\n        lineRenderer.startWidth = 0.02f;\r\n        lineRenderer.endWidth = 0.02f;\r\n        lineRenderer.useWorldSpace = true;\r\n\r\n        Vector3 laserOrigin = laserScanner.transform.position;\r\n        lineRenderer.SetPosition(0, laserOrigin);\r\n\r\n        for (int i = 0; i < scan.ranges.Length; i++)\r\n        {\r\n            float angle = scan.angle_min + i * scan.angle_increment;\r\n            float range = scan.ranges[i];\r\n\r\n            if (range > scan.range_min && range < scan.range_max)\r\n            {\r\n                Vector3 point = laserOrigin + new Vector3(\r\n                    range * Mathf.Cos(angle),\r\n                    range * Mathf.Sin(angle),\r\n                    0\r\n                );\r\n\r\n                // Transform to Unity coordinates\r\n                point = laserScanner.TransformDirection(point) + laserOrigin;\r\n                lineRenderer.SetPosition(i + 1, point);\r\n            }\r\n            else\r\n            {\r\n                lineRenderer.SetPosition(i + 1, laserOrigin);\r\n            }\r\n        }\r\n    }\r\n\r\n    private void ProcessCameraImage(sensor_msgs.Image image)\r\n    {\r\n        // Convert ROS image to Unity texture\r\n        StartCoroutine(ProcessImageCoroutine(image));\r\n    }\r\n\r\n    private System.Collections.IEnumerator ProcessImageCoroutine(sensor_msgs.Image image)\r\n    {\r\n        // Convert image data to Unity texture\r\n        Texture2D texture = new Texture2D(image.width, image.height, TextureFormat.RGB24, false);\r\n\r\n        // Load image data\r\n        byte[] imageData = ConvertRosImageToUnity(image);\r\n        texture.LoadRawTextureData(image.width, image.height, TextureFormat.RGB24, imageData);\r\n        texture.Apply();\r\n\r\n        // Apply texture to appropriate renderer\r\n        // This depends on your Unity scene setup\r\n        yield return null;\r\n    }\r\n\r\n    private byte[] ConvertRosImageToUnity(sensor_msgs.Image image)\r\n    {\r\n        // This is a simplified conversion\r\n        // In practice, you\'d handle different encodings and color formats\r\n        byte[] convertedData = new byte[image.width * image.height * 3];\r\n\r\n        // Convert RGB8 to Unity\'s RGB24 format\r\n        for (int i = 0; i < image.data.Length; i++)\r\n        {\r\n            convertedData[i] = image.data[i];\r\n        }\r\n\r\n        return convertedData;\r\n    }\r\n\r\n    #endregion\r\n\r\n    #region Custom Message Classes\r\n\r\n    [System.Serializable]\r\n    public class UnityInteractionMessage\r\n    {\r\n        public float timestamp;\r\n        public string event_type;\r\n        public string data;\r\n    }\r\n\r\n    #endregion\r\n\r\n    void OnDestroy()\r\n    {\r\n        DisconnectFromROS();\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(r.h3,{id:"822-advanced-ros-integration",children:"8.2.2 Advanced ROS Integration"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",metastring:'title="Advanced ROS Message Handler"',children:'using UnityEngine;\r\nusing RosSharp.RosBridgeClient;\r\nusing System.Collections.Generic;\r\n\r\npublic class AdvancedROSHandler : MonoBehaviour\r\n{\r\n    [Header("Advanced ROS Settings")]\r\n    public bool enableTFMonitoring = true;\r\n    public bool enableParameterSynchronization = true;\r\n    public bool enableActionServer = true;\r\n\r\n    private RosSocket rosSocket;\r\n    private Dictionary<string, Transform> tfFrames = new Dictionary<string, Transform>();\r\n\r\n    // TF monitoring\r\n    private string tfTopic = "/tf";\r\n    private string tfStaticTopic = "/tf_static";\r\n\r\n    // Parameter synchronization\r\n    private string paramGetService = "/get_parameters";\r\n    private string paramSetService = "/set_parameters";\r\n\r\n    // Action server\r\n    private string graspAction = "/grasp_execution";\r\n\r\n    void Start()\r\n    {\r\n        // Initialize advanced features\r\n        InitializeTFMonitoring();\r\n        InitializeParameterSync();\r\n        InitializeActionServer();\r\n    }\r\n\r\n    #region TF Monitoring\r\n\r\n    private void InitializeTFMonitoring()\r\n    {\r\n        if (!enableTFMonitoring) return;\r\n\r\n        // Subscribe to TF and static TF\r\n        rosSocket.Subscribe<tf2_msgs.TFMessage>(tfTopic, HandleTFMessage);\r\n        rosSocket.Subscribe<tf2_msgs.TFMessage>(tfStaticTopic, HandleTFMessage);\r\n    }\r\n\r\n    private void HandleTFMessage(tf2_msgs.TFMessage tfMsg)\r\n    {\r\n        foreach (var transform in tfMsg.transforms)\r\n        {\r\n            UpdateTFFrame(transform);\r\n        }\r\n    }\r\n\r\n    private void UpdateTFFrame(tf2_msgs.TransformStamped transformMsg)\r\n    {\r\n        string frameId = transformMsg.child_frame_id;\r\n\r\n        if (tfFrames.ContainsKey(frameId))\r\n        {\r\n            Transform tfTransform = tfFrames[frameId];\r\n\r\n            // Update transform based on ROS TF data\r\n            UpdateUnityTransform(tfTransform, transformMsg);\r\n        }\r\n        else\r\n        {\r\n            // Create new TF frame\r\n            CreateTFFrame(frameId, transformMsg);\r\n        }\r\n    }\r\n\r\n    private void UpdateUnityTransform(Transform unityTransform, tf2_msgs.TransformStamped tfTransform)\r\n    {\r\n        // Convert ROS transform to Unity transform\r\n        Vector3 position = new Vector3(\r\n            -tfTransform.transform.translation.y,\r\n            tfTransform.transform.translation.z,\r\n            tfTransform.transform.translation.x\r\n        );\r\n\r\n        Quaternion rotation = new Quaternion(\r\n            tfTransform.transform.rotation.z,\r\n            -tfTransform.transform.rotation.y,\r\n            -tfTransform.transform.rotation.x,\r\n            tfTransform.transform.rotation.w\r\n        );\r\n\r\n        unityTransform.localPosition = position;\r\n        unityTransform.localRotation = rotation;\r\n    }\r\n\r\n    private void CreateTFFrame(string frameId, tf2_msgs.TransformStamped transformMsg)\r\n    {\r\n        // Create new GameObject for TF frame\r\n        GameObject tfObject = new GameObject($"TF_{frameId}");\r\n        tfObject.transform.SetParent(this.transform);\r\n\r\n        // Store reference\r\n        tfFrames[frameId] = tfObject.transform;\r\n\r\n        // Apply initial transform\r\n        UpdateUnityTransform(tfObject.transform, transformMsg);\r\n    }\r\n\r\n    #endregion\r\n\r\n    #region Parameter Synchronization\r\n\r\n    private void InitializeParameterSync()\r\n    {\r\n        if (!enableParameterSynchronization) return;\r\n\r\n        // Get initial parameters\r\n        GetROSParameters();\r\n    }\r\n\r\n    private async void GetROSParameters()\r\n    {\r\n        if (rosSocket == null) return;\r\n\r\n        var request = new rcl_interfaces.GetParameters.Request\r\n        {\r\n            names = new string[] { "/unity/simulation_time", "/unity/robot_scale", "/unity/environment" }\r\n        };\r\n\r\n        var response = await rosSocket.CallService<rcl_interfaces.GetParameters, rcl_interfaces.GetParameters.Response>(\r\n            paramGetService, request);\r\n\r\n        if (response != null)\r\n        {\r\n            HandleParameterResponse(response);\r\n        }\r\n    }\r\n\r\n    private void HandleParameterResponse(rcl_interfaces.GetParameters.Response response)\r\n    {\r\n        foreach (var param in response.values)\r\n        {\r\n            UpdateUnityParameter(param);\r\n        }\r\n    }\r\n\r\n    private void UpdateUnityParameter(rcl_interfaces.Parameter param)\r\n    {\r\n        switch (param.name)\r\n        {\r\n            case "/unity/simulation_time":\r\n                if (param.double_value.HasValue)\r\n                {\r\n                    Time.timeScale = (float)param.double_value.Value;\r\n                }\r\n                break;\r\n\r\n            case "/unity/robot_scale":\r\n                if (param.double_value.HasValue)\r\n                {\r\n                    transform.localScale = Vector3.one * (float)param.double_value.Value;\r\n                }\r\n                break;\r\n\r\n            case "/unity/environment":\r\n                if (param.string_value != null)\r\n                {\r\n                    LoadUnityEnvironment(param.string_value);\r\n                }\r\n                break;\r\n        }\r\n    }\r\n\r\n    private void LoadUnityEnvironment(string environmentName)\r\n    {\r\n        // Load Unity environment based on parameter\r\n        Debug.Log($"Loading environment: {environmentName}");\r\n        // Implementation depends on your Unity setup\r\n    }\r\n\r\n    #endregion\r\n\r\n    #region Action Server\r\n\r\n    private void InitializeActionServer()\r\n    {\r\n        if (!enableActionServer) return;\r\n\r\n        // Implement action server functionality\r\n        Debug.Log("Unity Action Server initialized");\r\n    }\r\n\r\n    public async Task<bool> ExecuteGraspAction(geometry_msgs.PoseStamped targetPose)\r\n    {\r\n        // Send grasp action goal\r\n        var goal = new example_interfaces.GraspGoal\r\n        {\r\n            target_pose = targetPose,\r\n            grasp_type = "pinch",\r\n            max_force = 10.0\r\n        };\r\n\r\n        var response = await rosSocket.CallAction<example_interfaces.GraspGoal, example_interfaces.GraspResult>(\r\n            graspAction, goal);\r\n\r\n        return response?.success ?? false;\r\n    }\r\n\r\n    #endregion\r\n\r\n    #region Utility Functions\r\n\r\n    public Vector3 ConvertRosPointToUnity(geometry_msgs.Point rosPoint)\r\n    {\r\n        return new Vector3(\r\n            -rosPoint.y,\r\n            rosPoint.z,\r\n            rosPoint.x\r\n        );\r\n    }\r\n\r\n    public Quaternion ConvertRosQuaternionToUnity(geometry_msgs.Quaternion rosQuat)\r\n    {\r\n        return new Quaternion(\r\n            rosQuat.z,\r\n            -rosQuat.y,\r\n            -rosQuat.x,\r\n            rosQuat.w\r\n        );\r\n    }\r\n\r\n    public geometry_msgs.Point ConvertUnityPointToRos(Vector3 unityPoint)\r\n    {\r\n        return new geometry_msgs.Point\r\n        {\r\n            x = unityPoint.z,\r\n            y = -unityPoint.x,\r\n            z = unityPoint.y\r\n        };\r\n    }\r\n\r\n    public geometry_msgs.Quaternion ConvertUnityQuaternionToRos(Quaternion unityQuat)\r\n    {\r\n        return new geometry_msgs.Quaternion\r\n        {\r\n            x = -unityQuat.y,\r\n            y = -unityQuat.z,\r\n            z = unityQuat.x,\r\n            w = unityQuat.w\r\n        };\r\n    }\r\n\r\n    #endregion\r\n}\n'})}),"\n",(0,i.jsx)(r.h2,{id:"83-photorealistic-rendering",children:"8.3 Photorealistic Rendering"}),"\n",(0,i.jsx)(r.h3,{id:"831-high-definition-render-pipeline-hdrp",children:"8.3.1 High Definition Render Pipeline (HDRP)"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",metastring:'title="HDRP Configuration Script"',children:'using UnityEngine;\r\nusing UnityEngine.Rendering;\r\nusing UnityEngine.Rendering.HighDefinition;\r\n\r\n[ExecuteInEditMode]\r\npublic class RoboticsHDRPSetup : MonoBehaviour\r\n{\r\n    [Header("Volume Settings")]\r\n    public VolumeProfile globalVolume;\r\n\r\n    [Header("Lighting Settings")]\r\n    public LightingSetup lightingSetup;\r\n\r\n    [Header("Post-Processing")]\r\n    public bool enableBloom = true;\r\n    public bool enableMotionBlur = true;\r\n    public bool enableSSR = true; // Screen Space Reflections\r\n\r\n    void Start()\r\n    {\r\n        SetupHDRP();\r\n        ConfigureVolume();\r\n        SetupLighting();\r\n        ConfigureCamera();\r\n    }\r\n\r\n    private void SetupHDRP()\r\n    {\r\n        // Ensure HDRP asset is assigned\r\n        var hdrpAsset = GraphicsSettings.renderPipelineAsset as HDRenderPipelineAsset;\r\n        if (hdrpAsset == null)\r\n        {\r\n            Debug.LogWarning("HDRP Asset not found. Please assign HDRP Asset in Graphics Settings.");\r\n            return;\r\n        }\r\n\r\n        // Configure HDRP settings\r\n        ConfigureHDRPSettings(hdrpAsset);\r\n    }\r\n\r\n    private void ConfigureHDRPSettings(HDRenderPipelineAsset asset)\r\n    {\r\n        // Configure default frame settings\r\n        asset.defaultFrameSettings.InitDefaultFrameSettings();\r\n\r\n        // Enable features for robotics visualization\r\n        asset.defaultFrameSettingsSettings.xr.enabled = true; // VR/AR support\r\n        asset.defaultFrameSettingsSettings.invertColorMask = ColorMask.None;\r\n\r\n        // Configure ray tracing if available\r\n        if (asset.defaultFrameSettingsSettings.supportRaytracing)\r\n        {\r\n            asset.defaultFrameSettingsSettings.supportRaytracing = true;\r\n            asset.defaultFrameSettingsSettings.rayTracing = true;\r\n        }\r\n    }\r\n\r\n    private void ConfigureVolume()\r\n    {\r\n        if (globalVolume == null) return;\r\n\r\n        VolumeProfile profile = globalVolume.sharedProfile;\r\n        if (profile == null)\r\n        {\r\n            profile = ScriptableObject.CreateInstance<VolumeProfile>();\r\n            globalVolume.sharedProfile = profile;\r\n        }\r\n\r\n        // Clear existing settings\r\n        profile.components.Clear();\r\n\r\n        // Add bloom\r\n        if (enableBloom)\r\n        {\r\n            Bloom bloom = profile.Add<Bloom>(false);\r\n            bloom.threshold.value = 1f;\r\n            bloom.intensity.value = 0.5f;\r\n            bloom.tint.value = Color.white;\r\n            bloom.softKnee.value = 0.5f;\r\n        }\r\n\r\n        // Add motion blur\r\n        if (enableMotionBlur)\r\n        {\r\n            MotionBlur motionBlur = profile.Add<MotionBlur>(false);\r\n            motionBlur.intensity.value = 0.5f;\r\n            motionBlur.clamp.value = 0.05f;\r\n        }\r\n\r\n        // Add screen space reflections\r\n        if (enableSSR)\r\n        {\r\n            ScreenSpaceReflection ssr = profile.Add<ScreenSpaceReflection>(false);\r\n            ssr.intensity.value = 0.5f;\r\n            ssr.thickness.value = 0.5f;\r\n            ssr.distanceFade.value = 0.01f;\r\n        }\r\n\r\n        // Add ambient occlusion\r\n        AmbientOcclusion ao = profile.Add<AmbientOcclusion>(false);\r\n        ao.intensity.value = 0.5f;\r\n        ao.thickness.value = 1.0f;\r\n        ao.radius.value = 0.25f;\r\n    }\r\n\r\n    private void SetupLighting()\r\n    {\r\n        // Configure directional light (sun)\r\n        Light directionalLight = GameObject.FindObjectOfType<Light>();\r\n        if (directionalLight != null && directionalLight.type == LightType.Directional)\r\n        {\r\n            directionalLight.color = Color.white;\r\n            directionalLight.intensity = 1.2f;\r\n            directionalLight.shadowStrength = 0.8f;\r\n\r\n            // Configure HDRI sky for realistic lighting\r\n            RenderSettings.skybox = null; // Use HDRI sky\r\n            RenderSettings.ambientSkyColor = Color.white;\r\n        }\r\n\r\n        // Create lighting setup\r\n        CreateLightingSetup();\r\n    }\r\n\r\n    private void CreateLightingSetup()\r\n    {\r\n        if (lightingSetup != null)\r\n        {\r\n            lightingSetup.SetupForRobotics();\r\n        }\r\n        else\r\n        {\r\n            CreateDefaultLighting();\r\n        }\r\n    }\r\n\r\n    private void CreateDefaultLighting()\r\n    {\r\n        // Create additional lights for realistic rendering\r\n        CreateFillLight();\r\n        CreateRimLight();\r\n    }\r\n\r\n    private void CreateFillLight()\r\n    {\r\n        GameObject fillLightObj = new GameObject("Fill Light");\r\n        Light fillLight = fillLightObj.AddComponent<Light>();\r\n        fillLight.type = LightType.Directional;\r\n        fillLight.color = new Color(0.8f, 0.9f, 1f, 1f);\r\n        fillLight.intensity = 0.3f;\r\n        fillLight.shadows = LightShadows.None;\r\n\r\n        fillLightObj.transform.rotation = Quaternion.Euler(50f, -30f, 0f);\r\n    }\r\n\r\n    private void CreateRimLight()\r\n    {\r\n        GameObject rimLightObj = new GameObject("Rim Light");\r\n        Light rimLight = rimLightObj.AddComponent<Light>();\r\n        rimLight.type = LightType.Directional;\r\n        rimLight.color = new Color(1f, 0.9f, 0.8f, 1f);\r\n        rimLight.intensity = 0.4f;\r\n        rimLight.shadows = LightShadows.None;\r\n\r\n        rimLightObj.transform.rotation = Quaternion.Euler(10f, 120f, 0f);\r\n    }\r\n\r\n    private void ConfigureCamera()\r\n    {\r\n        Camera mainCamera = Camera.main;\r\n        if (mainCamera == null)\r\n        {\r\n            Debug.LogWarning("Main camera not found.");\r\n            return;\r\n        }\r\n\r\n        // Configure camera for robotics visualization\r\n        ConfigureMainCamera(mainCamera);\r\n    }\r\n\r\n    private void ConfigureMainCamera(Camera camera)\r\n    {\r\n        // Set camera parameters\r\n        camera.fieldOfView = 60f;\r\n        camera.nearClipPlane = 0.1f;\r\n        camera.farClipPlane = 100f;\r\n\r\n        // Add camera components for robotics\r\n        if (camera.GetComponent<RoboticsCameraController>() == null)\r\n        {\r\n            camera.gameObject.AddComponent<RoboticsCameraController>();\r\n        }\r\n\r\n        // Configure post-processing stack\r\n        ConfigureCameraPostProcessing(camera);\r\n    }\r\n\r\n    private void ConfigureCameraPostProcessing(Camera camera)\r\n    {\r\n        var additionalCameraData = camera.GetComponent<HDAdditionalCameraData>();\r\n        if (additionalCameraData == null)\r\n        {\r\n            additionalCameraData = camera.gameObject.AddComponent<HDAdditionalCameraData>();\r\n        }\r\n\r\n        // Enable post-processing\r\n        additionalCameraData.customRenderingSettings = true;\r\n\r\n        // Configure antialiasing\r\n        additionalCameraData.antialiasing = HDAdditionalCameraData.AntialiasingMode.FastApproximate;\r\n\r\n        // Configure depth of field if needed for cinematic shots\r\n        additionalCameraData.dofMode = HDAdditionalCameraData.DOFMode.Off;\r\n    }\r\n}\r\n\r\n[System.Serializable]\r\npublic class LightingSetup\r\n{\r\n    public Color ambientColor = Color.white;\r\n    public float ambientIntensity = 0.3f;\r\n    public Color sunColor = Color.white;\r\n    public float sunIntensity = 1.2f;\r\n    public Color skyTint = Color.white;\r\n    public float exposure = 1.0f;\r\n\r\n    public void SetupForRobotics()\r\n    {\r\n        RenderSettings.ambientLight = ambientColor;\r\n        RenderSettings.ambientIntensity = ambientIntensity;\r\n\r\n        // Configure sky for realistic outdoor rendering\r\n        DynamicGI.UpdateEnvironment();\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(r.h3,{id:"832-material-system-for-robotics",children:"8.3.2 Material System for Robotics"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",metastring:'title="Advanced Material System"',children:'using UnityEngine;\r\nusing UnityEngine.Rendering;\r\nusing UnityEngine.Rendering.HighDefinition;\r\n\r\npublic class RoboticsMaterialSystem : MonoBehaviour\r\n{\r\n    [Header("Material Settings")]\r\n    public Material metalMaterial;\r\n    public Material plasticMaterial;\r\n    public Material glassMaterial;\r\n    public Material carbonFiberMaterial;\r\n\r\n    [Header("Real-time Settings")]\r\n    public bool enableDynamicWear = true;\r\n    public bool enableEnvironmentalEffects = true;\r\n\r\n    void Start()\r\n    {\r\n        CreateAdvancedMaterials();\r\n        SetupMaterialProperties();\r\n    }\r\n\r\n    private void CreateAdvancedMaterials()\r\n    {\r\n        // Create metallic material with PBR properties\r\n        metalMaterial = CreateMetallicMaterial();\r\n\r\n        // Create plastic material with subsurface scattering\r\n        plasticMaterial = CreatePlasticMaterial();\r\n\r\n        // Create glass material with transparency\r\n        glassMaterial = CreateGlassMaterial();\r\n\r\n        // Create carbon fiber material with anisotropic properties\r\n        carbonFiberMaterial = CreateCarbonFiberMaterial();\r\n    }\r\n\r\n    private Material CreateMetallicMaterial()\r\n    {\r\n        Material mat = new Material(Shader.Find("HDRP/Lit"));\r\n\r\n        // PBR properties\r\n        mat.SetFloat("_Metallic", 1.0f);\r\n        mat.SetFloat("_Smoothness", 0.8f);\r\n        mat.SetColor("_BaseColor", new Color(0.7f, 0.7f, 0.8f, 1.0f));\r\n\r\n        // Anisotropic properties for brushed metal\r\n        mat.EnableKeyword("_ANISOTROPIC");\r\n        mat.SetFloat("_Anisotropy", 0.5f);\r\n        mat.SetFloat("_AnisotropyRotation", 0.0f);\r\n\r\n        return mat;\r\n    }\r\n\r\n    private Material CreatePlasticMaterial()\r\n    {\r\n        Material mat = new Material(Shader.Find("HDRP/Lit"));\r\n\r\n        // PBR properties for plastic\r\n        mat.SetFloat("_Metallic", 0.0f);\r\n        mat.SetFloat("_Smoothness", 0.4f);\r\n        mat.SetColor("_BaseColor", new Color(0.2f, 0.3f, 0.8f, 1.0f));\r\n\r\n        // Subsurface scattering\r\n        mat.EnableKeyword("_SUBSURFACE_SCATTERING");\r\n        mat.SetVector("_SubsurfaceRadius", new Vector4(0.1f, 0.1f, 0.1f, 0.0f));\r\n        mat.SetFloat("_SubsurfaceScattering", 0.5f);\r\n\r\n        return mat;\r\n    }\r\n\r\n    private Material CreateGlassMaterial()\r\n    {\r\n        Material mat = new Material(Shader.Find("HDRP/Lit"));\r\n\r\n        // Transparency\r\n        mat.SetFloat("_SurfaceType", 1.0f); // Transparent\r\n        mat.SetFloat("_BlendMode", 0.0f); // Alpha blending\r\n        mat.SetFloat("_AlphaCutoff", 0.01f);\r\n\r\n        // Refraction\r\n        mat.SetFloat("_IOR", 1.5f);\r\n        mat.SetFloat("_Transmission", 0.9f);\r\n\r\n        // Color\r\n        mat.SetColor("_BaseColor", new Color(0.8f, 0.9f, 1.0f, 0.2f));\r\n\r\n        return mat;\r\n    }\r\n\r\n    private Material CreateCarbonFiberMaterial()\r\n    {\r\n        Material mat = new Material(Shader.Find("HDRP/Lit"));\r\n\r\n        // Dark base with metallic highlights\r\n        mat.SetFloat("_Metallic", 0.8f);\r\n        mat.SetFloat("_Smoothness", 0.6f);\r\n        mat.SetColor("_BaseColor", new Color(0.05f, 0.05f, 0.05f, 1.0f));\r\n\r\n        // Anisotropic pattern\r\n        mat.EnableKeyword("_ANISOTROPIC");\r\n        mat.SetFloat("_Anisotropy", 0.8f);\r\n        mat.SetFloat("_AnisotropyRotation", 45.0f);\r\n\r\n        return mat;\r\n    }\r\n\r\n    private void SetupMaterialProperties()\r\n    {\r\n        // Enable material animations and effects\r\n        if (enableDynamicWear)\r\n        {\r\n            SetupWearSystem();\r\n        }\r\n\r\n        if (enableEnvironmentalEffects)\r\n        {\r\n            SetupEnvironmentalEffects();\r\n        }\r\n    }\r\n\r\n    private void SetupWearSystem()\r\n    {\r\n        // Create wear and tear materials\r\n        CreateWearMaterials();\r\n\r\n        // Initialize wear tracking\r\n        StartCoroutine(UpdateWearOverTime());\r\n    }\r\n\r\n    private void CreateWearMaterials()\r\n    {\r\n        // Create materials with procedural wear\r\n        // This would involve texture generation and material property updates\r\n    }\r\n\r\n    private System.Collections.IEnumerator UpdateWearOverTime()\r\n    {\r\n        while (true)\r\n        {\r\n            // Update material wear based on usage\r\n            UpdateMaterialWear();\r\n\r\n            yield return new WaitForSeconds(1.0f);\r\n        }\r\n    }\r\n\r\n    private void UpdateMaterialWear()\r\n    {\r\n        // Update smoothness based on usage\r\n        if (metalMaterial != null)\r\n        {\r\n            float currentSmoothness = metalMaterial.GetFloat("_Smoothness");\r\n            float wearFactor = Mathf.PingPong(Time.time * 0.1f, 0.2f);\r\n            metalMaterial.SetFloat("_Smoothness", currentSmoothness - wearFactor);\r\n        }\r\n    }\r\n\r\n    private void SetupEnvironmentalEffects()\r\n    {\r\n        // Add water droplets, dust, rust, etc.\r\n        // These effects would be applied dynamically based on environment\r\n    }\r\n\r\n    public Material GetMaterialForComponent(string componentType)\r\n    {\r\n        switch (componentType.ToLower())\r\n        {\r\n            case "metal":\r\n            case "aluminum":\r\n            case "steel":\r\n                return metalMaterial;\r\n\r\n            case "plastic":\r\n            case "polymer":\r\n                return plasticMaterial;\r\n\r\n            case "glass":\r\n            case "transparent":\r\n                return glassMaterial;\r\n\r\n            case "carbon":\r\n            case "carbon_fiber":\r\n                return carbonFiberMaterial;\r\n\r\n            default:\r\n                return metalMaterial;\r\n        }\r\n    }\r\n\r\n    public void ApplyMaterial(GameObject target, string materialType)\r\n    {\r\n        Material material = GetMaterialForComponent(materialType);\r\n        if (material != null)\r\n        {\r\n            Renderer[] renderers = target.GetComponentsInChildren<Renderer>();\r\n            foreach (var renderer in renderers)\r\n            {\r\n                renderer.material = material;\r\n            }\r\n        }\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(r.h2,{id:"84-interactive-robotics-applications",children:"8.4 Interactive Robotics Applications"}),"\n",(0,i.jsx)(r.h3,{id:"841-virtual-robot-control-interface",children:"8.4.1 Virtual Robot Control Interface"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-csharp",metastring:'title="Robot Control Interface"',children:'using UnityEngine;\r\nusing UnityEngine.UI;\r\nusing UnityEngine.EventSystems;\r\n\r\npublic class RobotControlInterface : MonoBehaviour\r\n{\r\n    [Header("Control References")]\r\n    public Joystick movementJoystick;\r\n    public Button graspingButton;\r\n    public Slider jointSliders;\r\n    public Text statusText;\r\n\r\n    [Header("Robot Information")]\r\n    public float maxLinearVelocity = 2.0f;\r\n    public float maxAngularVelocity = 1.0f;\r\n\r\n    private Vector2 movementInput = Vector2.zero;\r\n    private bool isGrasping = false;\r\n    private float[] jointPositions = new float[6];\r\n\r\n    // ROS communication\r\n    private UnityROSConnector rosConnector;\r\n\r\n    void Start()\r\n    {\r\n        // Initialize UI elements\r\n        InitializeUI();\r\n\r\n        // Find ROS connector\r\n        rosConnector = FindObjectOfType<UnityROSConnector>();\r\n\r\n        // Setup event handlers\r\n        SetupEventHandlers();\r\n    }\r\n\r\n    private void InitializeUI()\r\n    {\r\n        // Setup joystick\r\n        if (movementJoystick != null)\r\n        {\r\n            movementJoystick.DeadZone = 0.1f;\r\n            movementJoystick.AxisOptions = Joystick.AxisOption.Both;\r\n        }\r\n\r\n        // Setup sliders\r\n        if (jointSliders != null)\r\n        {\r\n            SetupJointSliders();\r\n        }\r\n\r\n        // Setup buttons\r\n        if (graspingButton != null)\r\n        {\r\n            graspingButton.onClick.AddListener(ToggleGrasping);\r\n        }\r\n    }\r\n\r\n    private void SetupJointSliders()\r\n    {\r\n        // Configure sliders for each joint\r\n        for (int i = 0; i < jointPositions.Length; i++)\r\n        {\r\n            jointSliders.minValue = -180f;\r\n            jointSliders.maxValue = 180f;\r\n            jointSliders.value = 0f;\r\n            jointSliders.onValueChanged.AddListener((value) => UpdateJointPosition(i, value));\r\n        }\r\n    }\r\n\r\n    private void SetupEventHandlers()\r\n    {\r\n        // Movement joystick\r\n        if (movementJoystick != null)\r\n        {\r\n            movementJoystick.OnValueUpdated += HandleMovementInput;\r\n        }\r\n\r\n        // Virtual buttons for other controls\r\n        SetupVirtualButtons();\r\n    }\r\n\r\n    private void SetupVirtualButtons()\r\n    {\r\n        // Create virtual buttons for additional controls\r\n        CreateVirtualButton("Home", new Vector2(100, 100), HomeRobot);\r\n        CreateVirtualButton("Stop", new Vector2(200, 100), StopRobot);\r\n        CreateVirtualButton("Emergency Stop", new Vector2(300, 100), EmergencyStop);\r\n    }\r\n\r\n    private void CreateVirtualButton(string label, Vector2 position, UnityEngine.Events.UnityAction callback)\r\n    {\r\n        GameObject buttonObj = new GameObject($"Button_{label}");\r\n        buttonObj.transform.SetParent(this.transform);\r\n\r\n        RectTransform rectTransform = buttonObj.AddComponent<RectTransform>();\r\n        rectTransform.anchoredPosition = position;\r\n        rectTransform.sizeDelta = new Vector2(80, 40);\r\n\r\n        Button button = buttonObj.AddComponent<Button>();\r\n        button.onClick.AddListener(callback);\r\n\r\n        Text buttonText = buttonObj.AddComponent<Text>();\r\n        buttonText.text = label;\r\n        buttonText.font = Resources.GetBuiltinResource<Font>("Arial.ttf");\r\n        buttonText.fontSize = 12;\r\n        buttonText.color = Color.white;\r\n        buttonText.alignment = TextAnchor.MiddleCenter;\r\n\r\n        // Style the button\r\n        Image buttonImage = buttonObj.AddComponent<Image>();\r\n        buttonImage.color = new Color(0.2f, 0.2f, 0.2f, 0.8f);\r\n\r\n        ButtonStateHelper stateHelper = buttonObj.AddComponent<ButtonStateHelper>();\r\n        stateHelper.SetupButton(button);\r\n    }\r\n\r\n    #region Control Methods\r\n\r\n    private void HandleMovementInput(Vector2 input)\r\n    {\r\n        movementInput = input;\r\n\r\n        // Send movement commands to robot\r\n        SendMovementCommand(input);\r\n    }\r\n\r\n    private void ToggleGrasping()\r\n    {\r\n        isGrasping = !isGrasping;\r\n\r\n        if (graspingButton != null)\r\n        {\r\n            Text buttonText = graspingButton.GetComponentInChildren<Text>();\r\n            if (buttonText != null)\r\n            {\r\n                buttonText.text = isGrasping ? "Release" : "Grasp";\r\n            }\r\n\r\n            Color buttonColor = isGrasping ? Color.red : Color.green;\r\n            Image buttonImage = graspingButton.GetComponent<Image>();\r\n            if (buttonImage != null)\r\n            {\r\n                buttonImage.color = buttonColor;\r\n            }\r\n        }\r\n\r\n        // Send grasping command\r\n        SendGraspingCommand(isGrasping);\r\n    }\r\n\r\n    private void UpdateJointPosition(int jointIndex, float angle)\r\n    {\r\n        jointPositions[jointIndex] = angle;\r\n\r\n        // Send joint position command\r\n        SendJointPositionCommand(jointIndex, angle);\r\n    }\r\n\r\n    private void HomeRobot()\r\n    {\r\n        // Move all joints to home position\r\n        for (int i = 0; i < jointPositions.Length; i++)\r\n        {\r\n            jointPositions[i] = 0f;\r\n            if (jointSliders != null)\r\n            {\r\n                jointSliders.value = 0f;\r\n            }\r\n        }\r\n\r\n        SendHomeCommand();\r\n    }\r\n\r\n    private void StopRobot()\r\n    {\r\n        // Stop all movement\r\n        movementInput = Vector2.zero;\r\n        isGrasping = false;\r\n\r\n        SendStopCommand();\r\n    }\r\n\r\n    private void EmergencyStop()\r\n    {\r\n        // Immediately stop all robot operations\r\n        EmergencyStopRobot();\r\n\r\n        // Show emergency stop status\r\n        if (statusText != null)\r\n        {\r\n            statusText.text = "EMERGENCY STOP ACTIVATED";\r\n            statusText.color = Color.red;\r\n        }\r\n    }\r\n\r\n    #endregion\r\n\r\n    #region ROS Communication\r\n\r\n    private void SendMovementCommand(Vector2 input)\r\n    {\r\n        if (rosConnector == null) return;\r\n\r\n        // Convert joystick input to velocity commands\r\n        float linearVelocity = input.y * maxLinearVelocity;\r\n        float angularVelocity = input.x * maxAngularVelocity;\r\n\r\n        // Create Twist message\r\n        var twistMsg = new geometry_msgs.Twist();\r\n        twistMsg.linear.x = linearVelocity;\r\n        twistMsg.angular.z = angularVelocity;\r\n\r\n        // Publish to ROS\r\n        rosSocket.Publish("/cmd_vel", twistMsg);\r\n\r\n        // Update status\r\n        UpdateStatus($"Velocity: linear={linearVelocity:F2}, angular={angularVelocity:F2}");\r\n    }\r\n\r\n    private void SendGraspingCommand(bool grasp)\r\n    {\r\n        if (rosConnector == null) return;\r\n\r\n        // Create gripper command\r\n        var gripperMsg = new GripperCommand();\r\n        gripperMsg.position = grasp ? 1.0f : 0.0f;\r\n        gripperMsg.max_effort = 10.0f;\r\n\r\n        // Publish to ROS\r\n        rosSocket.Publish("/gripper/command", gripperMsg);\r\n\r\n        UpdateStatus($"Grasping: {(grasp ? "Engaged" : "Released")}");\r\n    }\r\n\r\n    private void SendJointPositionCommand(int jointIndex, float angle)\r\n    {\r\n        if (rosConnector == null) return;\r\n\r\n        // Create joint command\r\n        var jointMsg = new sensor_msgs.JointState();\r\n        jointMsg.name = new string[] { $"joint_{jointIndex + 1}" };\r\n        jointMsg.position = new float[] { angle * Mathf.Deg2Rad };\r\n        jointMsg.velocity = new float[] { 0.0f };\r\n        jointMsg.effort = new float[] { 0.0f };\r\n\r\n        // Publish to ROS\r\n        rosSocket.Publish("/joint_states", jointMsg);\r\n    }\r\n\r\n    private void SendHomeCommand()\r\n    {\r\n        if (rosConnector == null) return;\r\n\r\n        // Create home command\r\n        var commandMsg = new std_msgs.String();\r\n        commandMsg.data = "home";\r\n\r\n        rosSocket.Publish("/robot/command", commandMsg);\r\n        UpdateStatus("Moving to home position");\r\n    }\r\n\r\n    private void SendStopCommand()\r\n    {\r\n        if (rosConnector == null) return;\r\n\r\n        // Create stop command\r\n        var commandMsg = new std_msgs.String();\r\n        commandMsg.data = "stop";\r\n\r\n        rosSocket.Publish("/robot/command", commandMsg);\r\n        UpdateStatus("Robot stopped");\r\n    }\r\n\r\n    private void EmergencyStopRobot()\r\n    {\r\n        if (rosConnector == null) return;\r\n\r\n        // Create emergency stop command\r\n        var eStopMsg = new std_msgs.Bool();\r\n        eStopMsg.data = true;\r\n\r\n        rosSocket.Publish("/emergency_stop", eStopMsg);\r\n        UpdateStatus("EMERGENCY STOP ACTIVATED");\r\n    }\r\n\r\n    #endregion\r\n\r\n    #region UI Updates\r\n\r\n    private void UpdateStatus(string message)\r\n    {\r\n        if (statusText != null)\r\n        {\r\n            statusText.text = message;\r\n            statusText.color = Color.white;\r\n        }\r\n    }\r\n\r\n    private void UpdateRobotStatus(float deltaTime)\r\n    {\r\n        // Update status based on robot state\r\n        if (movementInput.magnitude > 0.1f)\r\n        {\r\n            UpdateStatus($"Robot moving: v={movementInput.magnitude:F2}");\r\n        }\r\n        else if (isGrasping)\r\n        {\r\n            UpdateStatus("Robot grasping");\r\n        }\r\n        else\r\n        {\r\n            UpdateStatus("Robot idle");\r\n        }\r\n    }\r\n\r\n    #endregion\r\n\r\n    void Update()\r\n    {\r\n        // Update status display\r\n        UpdateRobotStatus(Time.deltaTime);\r\n    }\r\n\r\n    #region Utility Classes\r\n\r\n    [System.Serializable]\r\n    public class ButtonStateHelper : MonoBehaviour, IPointerEnterHandler, IPointerExitHandler, IPointerDownHandler, IPointerUpHandler\r\n    {\r\n        private Button button;\r\n        private Image image;\r\n        private Text text;\r\n\r\n        void Start()\r\n        {\r\n            button = GetComponent<Button>();\r\n            image = GetComponent<Image>();\r\n            text = GetComponentInChildren<Text>();\r\n        }\r\n\r\n        public void SetupButton(Button targetButton)\r\n        {\r\n            button = targetButton;\r\n            image = targetButton.GetComponent<Image>();\r\n            text = targetButton.GetComponentInChildren<Text>();\r\n        }\r\n\r\n        public void OnPointerEnter(PointerEventData eventData)\r\n        {\r\n            if (image != null)\r\n            {\r\n                image.color = Color.gray;\r\n            }\r\n        }\r\n\r\n        public void OnPointerExit(PointerEventData eventData)\r\n        {\r\n            if (image != null)\r\n            {\r\n                image.color = Color.white;\r\n            }\r\n        }\r\n\r\n        public void OnPointerDown(PointerEventData eventData)\r\n        {\r\n            if (image != null)\r\n            {\r\n                image.color = new Color(0.7f, 0.7f, 0.7f, 1f);\r\n            }\r\n        }\r\n\r\n        public void OnPointerUp(PointerEventData eventData)\r\n        {\r\n            if (image != null)\r\n            {\r\n                image.color = Color.white;\r\n            }\r\n        }\r\n    }\r\n\r\n    #endregion\r\n}\r\n\r\n// Custom message definitions for ROS communication\r\n[System.Serializable]\r\npublic class GripperCommand\r\n{\r\n    public float position;\r\n    public float max_effort;\r\n    public bool relative;\r\n}\n'})}),"\n",(0,i.jsx)(r.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(r.p,{children:"This chapter explored Unity's capabilities for robotics visualization, covering integration with ROS 2, photorealistic rendering, and interactive applications. Unity's strength lies in its rendering pipeline and cross-platform deployment, making it ideal for human-robot interaction, training, and commercial applications."}),"\n",(0,i.jsx)(r.p,{children:"Key takeaways:"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Unity offers superior rendering quality compared to traditional simulators"}),"\n",(0,i.jsx)(r.li,{children:"ROS-Unity integration enables bidirectional communication"}),"\n",(0,i.jsx)(r.li,{children:"HDRP provides photorealistic rendering for realistic visualization"}),"\n",(0,i.jsx)(r.li,{children:"Material systems enable realistic appearance of robot components"}),"\n",(0,i.jsx)(r.li,{children:"Interactive interfaces enable natural human-robot interaction"}),"\n",(0,i.jsx)(r.li,{children:"Cross-platform deployment enables mobile and web applications"}),"\n"]}),"\n",(0,i.jsx)(r.h2,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsx)(r.h3,{id:"exercise-81-unity-ros-integration",children:"Exercise 8.1: Unity-ROS Integration"}),"\n",(0,i.jsx)(r.p,{children:"Implement a complete Unity-ROS integration:"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Set up ROS-TCP-connector"}),"\n",(0,i.jsx)(r.li,{children:"Implement bidirectional communication"}),"\n",(0,i.jsx)(r.li,{children:"Handle multiple message types"}),"\n",(0,i.jsx)(r.li,{children:"Test with real robot data"}),"\n",(0,i.jsx)(r.li,{children:"Validate coordinate transformations"}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"exercise-82-photorealistic-rendering",children:"Exercise 8.2: Photorealistic Rendering"}),"\n",(0,i.jsx)(r.p,{children:"Create a photorealistic robot visualization:"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Configure HDRP settings"}),"\n",(0,i.jsx)(r.li,{children:"Create advanced PBR materials"}),"\n",(0,i.jsx)(r.li,{children:"Implement environmental effects"}),"\n",(0,i.jsx)(r.li,{children:"Add proper lighting setup"}),"\n",(0,i.jsx)(r.li,{children:"Measure rendering performance"}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"exercise-83-interactive-control-interface",children:"Exercise 8.3: Interactive Control Interface"}),"\n",(0,i.jsx)(r.p,{children:"Build an interactive robot control interface:"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Design intuitive UI controls"}),"\n",(0,i.jsx)(r.li,{children:"Implement virtual joysticks"}),"\n",(0,i.jsx)(r.li,{children:"Add visual feedback"}),"\n",(0,i.jsx)(r.li,{children:"Handle emergency stops"}),"\n",(0,i.jsx)(r.li,{children:"Validate usability"}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"exercise-84-material-system",children:"Exercise 8.4: Material System"}),"\n",(0,i.jsx)(r.p,{children:"Develop an advanced material system:"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Create realistic metal, plastic, glass materials"}),"\n",(0,i.jsx)(r.li,{children:"Implement wear and tear effects"}),"\n",(0,i.jsx)(r.li,{children:"Add environmental interactions"}),"\n",(0,i.jsx)(r.li,{children:"Optimize for performance"}),"\n",(0,i.jsx)(r.li,{children:"Test with different lighting"}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"exercise-85-cross-platform-deployment",children:"Exercise 8.5: Cross-Platform Deployment"}),"\n",(0,i.jsx)(r.p,{children:"Deploy Unity robotics application:"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Build for different platforms"}),"\n",(0,i.jsx)(r.li,{children:"Optimize for mobile devices"}),"\n",(0,i.jsx)(r.li,{children:"Implement WebGL deployment"}),"\n",(0,i.jsx)(r.li,{children:"Test performance across devices"}),"\n",(0,i.jsx)(r.li,{children:"Document deployment process"}),"\n"]}),"\n",(0,i.jsx)(r.h2,{id:"glossary-terms",children:"Glossary Terms"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"HDRP (High Definition Render Pipeline)"}),": Unity's high-end rendering system for photorealistic graphics"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"ROS-TCP-Connector"}),": Unity asset for ROS communication via WebSocket bridge"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"PBR (Physically Based Rendering)"}),": Material system that simulates real-world light behavior"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Material System"}),": Unity system for defining surface properties and appearance"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Volume System"}),": Unity's post-processing and visual effects system"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Anisotropic Materials"}),": Materials with direction-dependent surface properties"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Subsurface Scattering"}),": Light transport through translucent materials"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Motion Blur"}),": Visual effect simulating camera motion"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Screen Space Reflections"}),": Real-time reflection technique"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Virtual Reality (VR)"}),": Immersive visualization technology"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Augmented Reality (AR)"}),": Overlaying digital information on real world"]}),"\n"]})]})}function d(n={}){const{wrapper:r}={...(0,o.R)(),...n.components};return r?(0,i.jsx)(r,{...n,children:(0,i.jsx)(m,{...n})}):m(n)}},8453:(n,r,e)=>{e.d(r,{R:()=>a,x:()=>s});var t=e(6540);const i={},o=t.createContext(i);function a(n){const r=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(r):{...r,...n}},[r,n])}function s(n){let r;return r=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:a(n.components),t.createElement(o.Provider,{value:r},n.children)}}}]);